\documentclass{bioinfo}
\copyrightyear{2013}
\pubyear{2013}

\begin{document}
\firstpage{1}
\title[short Title]{Applications of Gibbs sampling to the Motif Finding Problem}
\author[Sample \textit{et~al}]{Alexander Hogue}
\address{}
\history{}
\editor{}

\maketitle

\begin{abstract}

\section{Motivation:}

\section{Results:}
DO SOME TESTS
GIVE ACCURACY

\section{Availability:}
The source code to our implementation of the Gibbs Sampler can be viewed and downloaded at <GITHUB LINK PLZ>

\end{abstract}

\section{Introduction}
\subsection{The Motif Finding Problem}
The Motif Finding Problem has great relevance to Bioinformatics, because <biology reasons TODO ACTUALLY ADD THIS>. 

In an instance of the motif finding problem, we are given $t$ DNA sequences, each of length $n$, and a length, $l$. Together they form a $t$ by $n$ DNA matrix.
The task is to find sequences of length $l$ in each of the $t$ DNA sequences with maximum "similarity". If each of the sequences shares a common substring, then the Motif Finding Problem reduces to simply finding a substring common to each of the $t$ DNA strings with length $l$. However, in the motif finding problem, we must account for \textit{mutations}. A \textit{mutation} accounts for an index in the motif string which may differ among the corresponding "motifs" in each of the DNA sequences. Mutations occur in DNA because CITE A PAPER HERE PLZ:::::::::. Further still, the number of these mutations that occur is typically not known \textit{a priori}. Another complication is the issue of "random" motifs. That is, strings that occur (possibly mutated slightly) in each DNA sequence. As the space of characters DNA strings consist of is small, as the number of DNA strings increase, the probability of a motif being generated by chance increases, especially for small values of $l$ relative to $n$. In these degenerate cases, the motif finding problem loses some meaning.

These patterns are of great scientific interest to those doing research in genetics because they correspond to sequences of DNA that control the activation of specific genes. CITE PAPER HERE PLZ

\section{Approach}
\subsection{Traditional methods of solving the Motif Finding Problem}
<Cite paper comparing running times>
Traditional methods of solving the Motif Finding Problem can take up to O(PLZ SOMETING) time, with the most efficient being O(PLZ) CITE SOME STUFF HERE As the number of sequences to sample ($t$) and their lengths ($n$) are often large, we seek a more efficient way of finding a motif within several DNA sequences, taking into account mutations. 

Our solution uses Gibbs Sampling, a Markov Chain Monte Carlo (MCMC) approach to probabilistically find the motif. We traverse an $l$-dimensional landscape searching for the global optimum in it, not dissimilar to the classic hill-climbing problem.
\begin{methods}
\section{Methods}
\subsection{The Gibbs Sampler}
Our Gibbs sampler's algorithm is described as follows.
For $t$ DNA samples of length $n$, searching for a motif of length $l$:\\
\begin{enumerate}
    \item Choose $t$ random starting points, one in the first $n - l$ nucleotides of each sequence.
    
    \item While convergence\footnote{See the next section for a discussion on convergence} has not been attained, do:
    \item Choose a DNA sequence randomly, call it $D$.
    \item Create a \textit{profile} from the $t - 1$ non chosen DNA sequences.
    \item For every starting position in the first $n - l$ positions in $D$, calculate the probability that the $l$-mer starting in each position is generated by the profile. This probabilty is given by:
        FORMULA OF PRODUCT OF P(letter in D is at position i in the profile)
    Furthermore, these probabilities form a distribution $P$, for each starting position's $l$-mer being generated by the profile.
    \item Choose a new starting position in $D$ by sampling from $P$. This is equivalent to taking a "step" in one of the $l$ dimensions of our landscape.
\end{enumerate}

We note that in general, traversing an n dimensional space takes exponential time, while Gibbs sampling provides a more efficient approach. The Algorithm performs a random walk in this space, similar to local search. The worst case running time is still the same exponential time, with a pathological (but not necessary to achieve the worst case time) input case being a landscape which is topologically an $l$-dimensional hyperplane\footnote{It's flat.}.
\subsection{Convergence}
The Gibbs Sampler is an algorithm that utilises hill climbing. As is the case with many such algorithms, it is difficult to tell when it has converged. We use the criteria as follows: if the profile has not changed in the last $k$ iterations, we are likely to be at an optima, be it local or global, so we say we have converged. For a given randomly selected staring point, depending on the landscape, it may be likely that we converge to a local optimum. To find the global optimum, we sample from many random starting points, and take the maxiumum height obtained over all convergences of these starting points. Both $k$ and the number of random starting points are taken as input parameters to the sampler.

\subsection{Implementation}
Our implementation of the Gibbs sampler and its testing program are written in Python 2.7. We recommend running the program with pypy, because hey why not it's faster.

\end{methods}

%\begin{figure}[!tpb]%figure1
%\centerline{\includegraphics{fig01.eps}}
%\caption{Caption, caption.}\label{fig:01}
%\end{figure}

\section{Discussion}
\subsection{Alternate Metrics for convergence.}
There is discussion on how best to constitute "convergence" for a gibbs sampler.
There may be merit in using \textit{simulated annealing}, a standard local search technique in which, to avoid becoming stuck in local optima, we probabilistically move away from the optima. CITE HERE. 
\subsection{Future work}
The alternate methods of convergence may have some merit, and a study comparing them may provide insight regarding their relative efficiencies. In addition, some DNA samples can be biased in their distribution of nucleotides, that is, the distribution is not uniform. In that situation, \textit{relative entropy} can be used to sample without bias.


\section*{Acknowledgement}

%\bibliographystyle{natbib}
%\bibliographystyle{achemnat}
%\bibliographystyle{plainnat}
%\bibliographystyle{abbrv}
%\bibliographystyle{bioinformatics}
%
%\bibliographystyle{plain}
%
%\bibliography{Document}


\begin{thebibliography}{}
\end{thebibliography}
\end{document}
